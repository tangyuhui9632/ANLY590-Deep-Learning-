{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TS-grKnC8TL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "fcaf5c17-2caa-44e8-b33b-c6a6719e39fc"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-01 14:44:25--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-12-01 14:44:25--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-12-01 14:44:25--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.07MB/s    in 6m 28s  \n",
            "\n",
            "2019-12-01 14:50:53 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixixfAG28r6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.models import Model, Sequential, load_model, model_from_config\n",
        "from keras.layers import Input, concatenate,InputSpec, Activation, Embedding, LSTM, Dense, Dropout, Lambda, Flatten, Bidirectional\n",
        "from keras.engine.topology import Layer\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import keras.backend as K\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import Word2Vec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMKw29Uo8oWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/youko70s/NeuralNets-DeepLearning/master/training_set.tsv'\n",
        "df = pd.read_csv(url, sep='\\t', encoding='ISO-8859-1')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xJouUWaC9v4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dict(text):\n",
        "    print(\"create_dict\")\n",
        "    word_index = {}\n",
        "    for sentence in text:\n",
        "        for word in sentence:\n",
        "            if word not in word_index:\n",
        "                word_index[word] = len(word_index)\n",
        "    word_index['unk'] = len(word_index)\n",
        "    return word_index\n",
        "\n",
        "\n",
        "def essay_to_index(text, word_index):\n",
        "    text_index = []\n",
        "    for essay in text:\n",
        "        essay_index = []\n",
        "        for word in essay:\n",
        "            essay_index.append(word_index[word])\n",
        "        text_index.append(essay_index)\n",
        "    return text_index\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFxOVAS3DEO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings_index():\n",
        "    embeddings_index = {}\n",
        "    f = open('glove.6B.100d.txt', 'r', encoding='UTF-8')\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.array(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()\n",
        "    return embeddings_index\n",
        "\n",
        "\n",
        "def embeddings_matrix(embeddings_index, word_index, embedding_dim):\n",
        "    nb_words = len(word_index)\n",
        "    embedding_matrix = np.zeros((nb_words + 1, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i > nb_words:\n",
        "            continue\n",
        "        embeddings_vector = embeddings_index.get(word)\n",
        "        if embeddings_vector is not None:\n",
        "            embedding_matrix[i] = embeddings_vector\n",
        "    return embedding_matrix\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzX24gGHDGBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clean_essays(Text):\n",
        "    clean_essays = []\n",
        "    for essay in Text:\n",
        "        clean_essays.append(essay_to_wordlist(essay, remove_stopwords=True))\n",
        "    return clean_essays\n",
        "\n",
        "\n",
        "def essay_to_wordlist(essay_v, remove_stopwords):\n",
        "    \"\"\"Remove the tagged labels and word tokenize the sentence.\"\"\"\n",
        "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n",
        "    words = essay_v.lower().split()\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "    return (words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAETp9Wd9Qy0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a7f4f714-a7eb-4585-b34c-8151eee34c98"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9VGxMtS9UWa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5e85ad99-ee0d-46e8-bee9-f11edc7281dd"
      },
      "source": [
        "nltk.download('punct')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading punct: Package 'punct' not found in index\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhoKuD89DHvE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f4388b7a-d7ef-48b9-9905-8dc4df0078b3"
      },
      "source": [
        "Score = df['domain1_score']\n",
        "Text = df['essay']\n",
        "word_index = create_dict(essays)\n",
        "\n",
        "essays = get_clean_essays(Text)\n",
        "\n",
        "maxlen = 0\n",
        "for essay in essays:\n",
        "  if len(essay)>maxlen:\n",
        "    maxlen = len(essay)\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_essay_length = maxlen\n",
        "essays_in_index = np.array(essay_to_index(essays, word_index))\n",
        "essays_in_index = pad_sequences(essays_in_index, maxlen=max_essay_length)\n",
        "\n",
        "\n",
        "embeddings_index = get_embeddings_index()\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "create_dict\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a47N-iUNqdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "28766c61-628a-45a5-d94f-3c3c864954ec"
      },
      "source": [
        "len(embeddings_index)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFjU0PPADOb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_words = len(word_index)\n",
        "embedding_matrix = np.zeros((nb_words + 1, 100))\n",
        "for word, i in word_index.items():\n",
        "    if i > nb_words:\n",
        "        continue\n",
        "    embeddings_vector = embeddings_index.get(word)\n",
        "    if embeddings_vector is not None:\n",
        "        embedding_matrix[i] = embeddings_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5G08pfY-zNf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "95072015-fab7-42e9-efab-bb600d5fd468"
      },
      "source": [
        "maxlen"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "524"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBHNwNrODQXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    print('Build model...')\n",
        "    #model = Sequential()\n",
        "    text_input = Input(shape=(max_essay_length, ), name='text_input')\n",
        "    # feature_input = Input(shape=(num_feature, ), name='feature_input')\n",
        "    # model = Sequential()\n",
        "    \n",
        "    embedding_layer = Embedding(input_dim=len(word_index) + 1,\n",
        "                                output_dim=100,\n",
        "                                weights=[embedding_matrix],\n",
        "                                input_length=max_essay_length,\n",
        "                                trainable=True,\n",
        "                                dropout=0)\n",
        "    embedding = embedding_layer(text_input)\n",
        "    # model.add(embedding)\n",
        "    #lstm_out = LSTM(64, dropout=0.1, recurrent_dropout=0.1, return_sequences=True)(embedding)\n",
        "    lstm_out = LSTM(64, dropout=0.1, recurrent_dropout=0.1, return_sequences=False)(embedding)\n",
        "    #model.add(LSTM(128, dropout=0.1, recurrent_dropout=0.1, return_sequences=False))\n",
        "    #att = AttentionWithContext(lstm_out)\n",
        "    #att = Addition(att)\n",
        "    output = Dense(1, activation='relu')(lstm_out)\n",
        "\n",
        "    #add attention\n",
        "    #model.add(AttentionWithContext())\n",
        "    #model.add(Addition())\n",
        "    #model.add(Dense(1, activation='sigmoid'))\n",
        "    model = Model(inputs=text_input, outputs=output)\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVuXOnB8DSHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "d6b5950a-ca76-4926-f707-6be81be62dc2"
      },
      "source": [
        "get_model()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      (None, 524)               0         \n",
            "_________________________________________________________________\n",
            "embedding_36 (Embedding)     (None, 524, 100)          3785600   \n",
            "_________________________________________________________________\n",
            "lstm_47 (LSTM)               (None, 64)                42240     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 3,827,905\n",
            "Trainable params: 3,827,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.training.Model at 0x7fde34928780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3qcMDEiDUby",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "4e976c82-7918-46f5-cb64-3e2fa94708d1"
      },
      "source": [
        "results = []\n",
        "score_predict_list = []\n",
        "count = 1\n",
        "cv = KFold(n_splits=3, shuffle=True)\n",
        "for train, test in cv.split(essays_in_index):\n",
        "    text_train, text_test = essays_in_index[train], essays_in_index[test]\n",
        "    label_train, label_test = Score.iloc[train], Score.iloc[test]\n",
        "\n",
        "    model = get_model()\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "    history = model.fit(text_train, label_train, batch_size=16, epochs=20)\n",
        "\n",
        "    score_predict = model.predict(text_test)\n",
        "    score_predict = np.around(score_predict)\n",
        "    result = cohen_kappa_score(label_test.values, score_predict, weights='quadratic')\n",
        "    print(\"Kappa Score: {}\".format(result))\n",
        "    results.append(result)\n",
        "\n",
        "    count += 1\n",
        "\n",
        "print(\"Average Kappa score after a 5-fold cross validation: \", np.around(np.array(results).mean(), decimals=4))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_input (InputLayer)      (None, 524)               0         \n",
            "_________________________________________________________________\n",
            "embedding_39 (Embedding)     (None, 524, 100)          3785600   \n",
            "_________________________________________________________________\n",
            "lstm_50 (LSTM)               (None, 64)                42240     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 3,827,905\n",
            "Trainable params: 3,827,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "8650/8650 [==============================] - 273s 32ms/step - loss: 40.9745 - mean_absolute_error: 3.3963\n",
            "Epoch 2/20\n",
            "8304/8650 [===========================>..] - ETA: 10s - loss: 14.1083 - mean_absolute_error: 1.9543"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BABtCHmgX1Fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}