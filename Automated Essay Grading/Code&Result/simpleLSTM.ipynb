{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "heCvJUqtgUkm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "5fff67db-d67d-474b-99ab-ce8e401837e5"
      },
      "source": [
        "# import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn import ensemble\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "from keras.models import Sequential, load_model, model_from_config\n",
        "import keras.backend as K"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t77k5Xh5iqgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "18425d93-309d-4d87-a0e0-b1d5e727a755"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5AOKfyygYmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/youko70s/NeuralNets-DeepLearning/master/training_set.tsv'\n",
        "df = pd.read_csv(url, sep='\\t', encoding='ISO-8859-1')\n",
        "\n",
        "scores = df['domain1_score']\n",
        "dataset = df.loc[:,['essay_id', 'essay_set', 'essay', 'domain1_score']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjnrnj2lghsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generating word tokens after removing characters other than alphabets, converting them to lower case and\n",
        "# removing stopwords from the text\n",
        "def word_tokens(text):\n",
        "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
        "    words = text.lower().split()\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    words = [w for w in words if not w in stop_words]\n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXTCF7EcgybK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentence_tokens(essay_text):\n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    sent_tokens = tokenizer.tokenize(essay_text.strip())\n",
        "    sentences = []\n",
        "    for sent_token in sent_tokens:\n",
        "        if len(sent_token) > 0:\n",
        "            sentences.append(word_tokens(sent_token))\n",
        "    return sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-JpqxiCg4BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to create feature vectors \n",
        "def makeFeatureVec(words, model, num_features):\n",
        "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
        "    num_words = 0.\n",
        "    index2word_set = set(model.wv.index2word)\n",
        "    for word in words:\n",
        "        if word in index2word_set:\n",
        "            num_words += 1\n",
        "            featureVec = np.add(featureVec,model[word])        \n",
        "    featureVec = np.divide(featureVec,num_words)\n",
        "    return featureVec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzKmEEJXg_BT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to generate word vectors \n",
        "def getAvgFeatureVecs(essays, model, num_features):\n",
        "    counter = 0\n",
        "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
        "    for essay_text in essays:\n",
        "        essayFeatureVecs[counter] = makeFeatureVec(essay_text, model, num_features)\n",
        "        counter = counter + 1\n",
        "    return essayFeatureVecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlrQOqjAhDPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build NN model \n",
        "def get_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(500, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 500], return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tqF7ggmif94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set cross validation \n",
        "cv = KFold(n_splits=5, shuffle=True)\n",
        "results = []\n",
        "y_pred_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KFtPDLoikby",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "49d32559-279a-4c8f-8299-0956d6641a6d"
      },
      "source": [
        "print(cv)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KFold(n_splits=5, random_state=None, shuffle=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPU5GpkPimEz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d1a320c-6885-44a5-de1d-372f06cf7e3c"
      },
      "source": [
        "count = 1\n",
        "for traincv, testcv in cv.split(dataset):\n",
        "    print(\"###################Fold {}##################\\n\".format(count))\n",
        "    X_test, X_train, y_test, y_train = dataset.iloc[testcv], dataset.iloc[traincv], scores.iloc[testcv], scores.iloc[traincv]\n",
        "    \n",
        "    train_essays = X_train['essay']\n",
        "    test_essays = X_test['essay']\n",
        "    \n",
        "    sentences = []\n",
        "    \n",
        "    for essay in train_essays:\n",
        "            # Obtaining all sentences from the training set of essays.\n",
        "            sentences += sentence_tokens(essay)\n",
        "            \n",
        "    # Initializing variables for word2vec model.\n",
        "    num_features = 500 \n",
        "    min_word_count = 40\n",
        "    num_workers = 4\n",
        "    context = 10\n",
        "    downsampling = 1e-3\n",
        "\n",
        "    print(\"Training Word2Vec Model...\")\n",
        "    model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
        "\n",
        "    model.init_sims(replace=True)\n",
        "    model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
        "\n",
        "    clean_train_essays = []\n",
        "    \n",
        "    # Generate training and testing data word vectors.\n",
        "    for essay_text in train_essays:\n",
        "        clean_train_essays.append(word_tokens(essay_text))\n",
        "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
        "    \n",
        "    clean_test_essays = []\n",
        "    for essay_text in test_essays:\n",
        "        clean_test_essays.append(word_tokens(essay_text))\n",
        "    testDataVecs = getAvgFeatureVecs(clean_test_essays, model, num_features)\n",
        "    \n",
        "    trainDataVecs = np.array(trainDataVecs)\n",
        "    testDataVecs = np.array(testDataVecs)\n",
        "    # Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
        "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
        "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "    \n",
        "    lstm_model = get_model()\n",
        "    lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=50)\n",
        "    #lstm_model.load_weights('./model_weights/final_lstm.h5')\n",
        "    y_pred = lstm_model.predict(testDataVecs)\n",
        "    \n",
        "    # Round y_pred to the nearest integer.\n",
        "    y_pred = np.around(y_pred)\n",
        "    # Mean squared error\n",
        "    print(\"Mean squared error: {0:.2f}\".format(mean_squared_error(y_test.values, y_pred)))\n",
        "    # Explained variance score: 1 is perfect prediction\n",
        "    print('Explained Variance: {0:.2f}'.format(explained_variance_score(y_test.values, y_pred)))  \n",
        "    #Cohen's kappa score\n",
        "    result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
        "    print(\"Kappa Score: {0:.2f}\".format(result))\n",
        "    results.append(result)\n",
        "\n",
        "    count += 1"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "###################Fold 1##################\n",
            "\n",
            "Training Word2Vec Model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_7 (LSTM)                (None, 1, 500)            2002000   \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 64)                144640    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,146,705\n",
            "Trainable params: 2,146,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10380/10380 [==============================] - 15s 1ms/step - loss: 61.5176 - mean_absolute_error: 4.1766\n",
            "Epoch 2/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 37.8270 - mean_absolute_error: 3.4079\n",
            "Epoch 3/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 30.7538 - mean_absolute_error: 3.2937\n",
            "Epoch 4/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 28.8957 - mean_absolute_error: 3.2592\n",
            "Epoch 5/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 26.7522 - mean_absolute_error: 3.1105\n",
            "Epoch 6/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 24.8045 - mean_absolute_error: 2.9550\n",
            "Epoch 7/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 23.4321 - mean_absolute_error: 2.8313\n",
            "Epoch 8/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 20.5883 - mean_absolute_error: 2.7188\n",
            "Epoch 9/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 19.1709 - mean_absolute_error: 2.6634\n",
            "Epoch 10/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 16.7622 - mean_absolute_error: 2.4996\n",
            "Epoch 11/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 15.5375 - mean_absolute_error: 2.4088\n",
            "Epoch 12/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 14.3133 - mean_absolute_error: 2.3161\n",
            "Epoch 13/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 13.4640 - mean_absolute_error: 2.2671\n",
            "Epoch 14/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 12.8163 - mean_absolute_error: 2.2071\n",
            "Epoch 15/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 12.1615 - mean_absolute_error: 2.1432\n",
            "Epoch 16/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 11.6394 - mean_absolute_error: 2.1001\n",
            "Epoch 17/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 12.1378 - mean_absolute_error: 2.1022\n",
            "Epoch 18/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 11.1759 - mean_absolute_error: 2.0291\n",
            "Epoch 19/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 10.3105 - mean_absolute_error: 1.9522\n",
            "Epoch 20/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 9.9520 - mean_absolute_error: 1.8970\n",
            "Epoch 21/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 10.5863 - mean_absolute_error: 1.9061\n",
            "Epoch 22/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 9.7504 - mean_absolute_error: 1.8501\n",
            "Epoch 23/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 9.7705 - mean_absolute_error: 1.8446\n",
            "Epoch 24/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 9.6267 - mean_absolute_error: 1.8155\n",
            "Epoch 25/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 9.4098 - mean_absolute_error: 1.8116\n",
            "Epoch 26/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 9.1617 - mean_absolute_error: 1.7718\n",
            "Epoch 27/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 9.2237 - mean_absolute_error: 1.7658\n",
            "Epoch 28/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 8.9054 - mean_absolute_error: 1.7224\n",
            "Epoch 29/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 8.9328 - mean_absolute_error: 1.6432\n",
            "Epoch 30/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 8.7009 - mean_absolute_error: 1.6259\n",
            "Epoch 31/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 8.6469 - mean_absolute_error: 1.6126\n",
            "Epoch 32/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 8.6182 - mean_absolute_error: 1.5878\n",
            "Epoch 33/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 8.6680 - mean_absolute_error: 1.6030\n",
            "Epoch 34/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 8.2647 - mean_absolute_error: 1.5724\n",
            "Epoch 35/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 8.3654 - mean_absolute_error: 1.5701\n",
            "Epoch 36/50\n",
            "10380/10380 [==============================] - 13s 1ms/step - loss: 7.8321 - mean_absolute_error: 1.5413\n",
            "Epoch 37/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 8.4208 - mean_absolute_error: 1.5729\n",
            "Epoch 38/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 8.0702 - mean_absolute_error: 1.5580\n",
            "Epoch 39/50\n",
            "10380/10380 [==============================] - 13s 1ms/step - loss: 7.9665 - mean_absolute_error: 1.5351\n",
            "Epoch 40/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 8.0830 - mean_absolute_error: 1.5325\n",
            "Epoch 41/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 7.9708 - mean_absolute_error: 1.5269\n",
            "Epoch 42/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 7.9691 - mean_absolute_error: 1.5458\n",
            "Epoch 43/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 7.9809 - mean_absolute_error: 1.5348\n",
            "Epoch 44/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 8.0383 - mean_absolute_error: 1.5257\n",
            "Epoch 45/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 8.0254 - mean_absolute_error: 1.5257\n",
            "Epoch 46/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 7.6776 - mean_absolute_error: 1.5058\n",
            "Epoch 47/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 7.6197 - mean_absolute_error: 1.4906\n",
            "Epoch 48/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 7.6899 - mean_absolute_error: 1.4954\n",
            "Epoch 49/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 7.8361 - mean_absolute_error: 1.5045\n",
            "Epoch 50/50\n",
            "10380/10380 [==============================] - 12s 1ms/step - loss: 7.6003 - mean_absolute_error: 1.4910\n",
            "Mean squared error: 5.35\n",
            "Explained Variance: 0.93\n",
            "Kappa Score: 0.96\n",
            "###################Fold 2##################\n",
            "\n",
            "Training Word2Vec Model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_9 (LSTM)                (None, 1, 500)            2002000   \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 64)                144640    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,146,705\n",
            "Trainable params: 2,146,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10381/10381 [==============================] - 15s 1ms/step - loss: 57.2655 - mean_absolute_error: 4.0529\n",
            "Epoch 2/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 36.0316 - mean_absolute_error: 3.3893\n",
            "Epoch 3/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 31.1092 - mean_absolute_error: 3.3191\n",
            "Epoch 4/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 28.9325 - mean_absolute_error: 3.2344\n",
            "Epoch 5/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 27.1102 - mean_absolute_error: 3.0873\n",
            "Epoch 6/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 24.2097 - mean_absolute_error: 2.8627\n",
            "Epoch 7/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 21.2125 - mean_absolute_error: 2.6706\n",
            "Epoch 8/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 18.2606 - mean_absolute_error: 2.4563\n",
            "Epoch 9/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 16.7799 - mean_absolute_error: 2.3335\n",
            "Epoch 10/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 15.0005 - mean_absolute_error: 2.2251\n",
            "Epoch 11/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 14.5207 - mean_absolute_error: 2.1648\n",
            "Epoch 12/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 12.6438 - mean_absolute_error: 2.0562\n",
            "Epoch 13/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 12.7120 - mean_absolute_error: 2.0274\n",
            "Epoch 14/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 12.0924 - mean_absolute_error: 1.9845\n",
            "Epoch 15/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 11.5578 - mean_absolute_error: 1.9525\n",
            "Epoch 16/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 11.8317 - mean_absolute_error: 1.9565\n",
            "Epoch 17/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 10.9085 - mean_absolute_error: 1.8735\n",
            "Epoch 18/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 10.6398 - mean_absolute_error: 1.8483\n",
            "Epoch 19/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 10.1960 - mean_absolute_error: 1.8121\n",
            "Epoch 20/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 10.4301 - mean_absolute_error: 1.8049\n",
            "Epoch 21/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 10.0859 - mean_absolute_error: 1.7949\n",
            "Epoch 22/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.5146 - mean_absolute_error: 1.7273\n",
            "Epoch 23/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.6852 - mean_absolute_error: 1.7262\n",
            "Epoch 24/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.4168 - mean_absolute_error: 1.7077\n",
            "Epoch 25/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.2198 - mean_absolute_error: 1.6760\n",
            "Epoch 26/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.8433 - mean_absolute_error: 1.6409\n",
            "Epoch 27/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.7127 - mean_absolute_error: 1.6413\n",
            "Epoch 28/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.8368 - mean_absolute_error: 1.6238\n",
            "Epoch 29/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.5861 - mean_absolute_error: 1.6227\n",
            "Epoch 30/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.7131 - mean_absolute_error: 1.6136\n",
            "Epoch 31/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.7245 - mean_absolute_error: 1.6089\n",
            "Epoch 32/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.1543 - mean_absolute_error: 1.5708\n",
            "Epoch 33/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.2458 - mean_absolute_error: 1.5754\n",
            "Epoch 34/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.2850 - mean_absolute_error: 1.5768\n",
            "Epoch 35/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.0709 - mean_absolute_error: 1.5726\n",
            "Epoch 36/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.2092 - mean_absolute_error: 1.5498\n",
            "Epoch 37/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.5283 - mean_absolute_error: 1.5618\n",
            "Epoch 38/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.0283 - mean_absolute_error: 1.5417\n",
            "Epoch 39/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.0844 - mean_absolute_error: 1.5528\n",
            "Epoch 40/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.8535 - mean_absolute_error: 1.5367\n",
            "Epoch 41/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.1254 - mean_absolute_error: 1.5531\n",
            "Epoch 42/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.6718 - mean_absolute_error: 1.5181\n",
            "Epoch 43/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.7163 - mean_absolute_error: 1.5317\n",
            "Epoch 44/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.5632 - mean_absolute_error: 1.5062\n",
            "Epoch 45/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.7946 - mean_absolute_error: 1.5201\n",
            "Epoch 46/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.4032 - mean_absolute_error: 1.4907\n",
            "Epoch 47/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.5671 - mean_absolute_error: 1.5023\n",
            "Epoch 48/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.4294 - mean_absolute_error: 1.5031\n",
            "Epoch 49/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.4307 - mean_absolute_error: 1.4929\n",
            "Epoch 50/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.5545 - mean_absolute_error: 1.4937\n",
            "Mean squared error: 6.70\n",
            "Explained Variance: 0.92\n",
            "Kappa Score: 0.96\n",
            "###################Fold 3##################\n",
            "\n",
            "Training Word2Vec Model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_11 (LSTM)               (None, 1, 500)            2002000   \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 64)                144640    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,146,705\n",
            "Trainable params: 2,146,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10381/10381 [==============================] - 16s 2ms/step - loss: 58.6125 - mean_absolute_error: 4.0624\n",
            "Epoch 2/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 36.5700 - mean_absolute_error: 3.3696\n",
            "Epoch 3/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 31.1353 - mean_absolute_error: 3.2902\n",
            "Epoch 4/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 28.9987 - mean_absolute_error: 3.2139\n",
            "Epoch 5/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 26.9561 - mean_absolute_error: 3.0418\n",
            "Epoch 6/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 23.0234 - mean_absolute_error: 2.7827\n",
            "Epoch 7/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 19.2487 - mean_absolute_error: 2.5444\n",
            "Epoch 8/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 17.4151 - mean_absolute_error: 2.3838\n",
            "Epoch 9/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 15.6156 - mean_absolute_error: 2.2791\n",
            "Epoch 10/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 14.9228 - mean_absolute_error: 2.1989\n",
            "Epoch 11/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 13.2830 - mean_absolute_error: 2.0924\n",
            "Epoch 12/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 12.3559 - mean_absolute_error: 2.0362\n",
            "Epoch 13/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 12.0295 - mean_absolute_error: 1.9839\n",
            "Epoch 14/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 11.8599 - mean_absolute_error: 1.9775\n",
            "Epoch 15/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 11.6793 - mean_absolute_error: 1.9420\n",
            "Epoch 16/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 11.6921 - mean_absolute_error: 1.9463\n",
            "Epoch 17/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 10.3966 - mean_absolute_error: 1.8415\n",
            "Epoch 18/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 11.2861 - mean_absolute_error: 1.8836\n",
            "Epoch 19/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 10.6628 - mean_absolute_error: 1.8465\n",
            "Epoch 20/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.9400 - mean_absolute_error: 1.7923\n",
            "Epoch 21/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 10.2165 - mean_absolute_error: 1.7878\n",
            "Epoch 22/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.6324 - mean_absolute_error: 1.7402\n",
            "Epoch 23/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.7047 - mean_absolute_error: 1.7304\n",
            "Epoch 24/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.6553 - mean_absolute_error: 1.7337\n",
            "Epoch 25/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.3590 - mean_absolute_error: 1.7019\n",
            "Epoch 26/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.1537 - mean_absolute_error: 1.6768\n",
            "Epoch 27/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.9617 - mean_absolute_error: 1.6566\n",
            "Epoch 28/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.5820 - mean_absolute_error: 1.6333\n",
            "Epoch 29/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.3690 - mean_absolute_error: 1.6127\n",
            "Epoch 30/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.4277 - mean_absolute_error: 1.5978\n",
            "Epoch 31/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.5909 - mean_absolute_error: 1.6144\n",
            "Epoch 32/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.5899 - mean_absolute_error: 1.6036\n",
            "Epoch 33/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.7421 - mean_absolute_error: 1.6067\n",
            "Epoch 34/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.3408 - mean_absolute_error: 1.5972\n",
            "Epoch 35/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.2251 - mean_absolute_error: 1.5757\n",
            "Epoch 36/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.1720 - mean_absolute_error: 1.5835\n",
            "Epoch 37/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.3543 - mean_absolute_error: 1.5648\n",
            "Epoch 38/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.5574 - mean_absolute_error: 1.5858\n",
            "Epoch 39/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.8447 - mean_absolute_error: 1.5456\n",
            "Epoch 40/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.6015 - mean_absolute_error: 1.5412\n",
            "Epoch 41/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.3216 - mean_absolute_error: 1.5579\n",
            "Epoch 42/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.9769 - mean_absolute_error: 1.5488\n",
            "Epoch 43/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.2384 - mean_absolute_error: 1.5680\n",
            "Epoch 44/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.4382 - mean_absolute_error: 1.5077\n",
            "Epoch 45/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.8183 - mean_absolute_error: 1.5311\n",
            "Epoch 46/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.9883 - mean_absolute_error: 1.5486\n",
            "Epoch 47/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.9688 - mean_absolute_error: 1.5330\n",
            "Epoch 48/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.7942 - mean_absolute_error: 1.5425\n",
            "Epoch 49/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.3164 - mean_absolute_error: 1.5100\n",
            "Epoch 50/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.7939 - mean_absolute_error: 1.5319\n",
            "Mean squared error: 6.78\n",
            "Explained Variance: 0.92\n",
            "Kappa Score: 0.96\n",
            "###################Fold 4##################\n",
            "\n",
            "Training Word2Vec Model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_13 (LSTM)               (None, 1, 500)            2002000   \n",
            "_________________________________________________________________\n",
            "lstm_14 (LSTM)               (None, 64)                144640    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,146,705\n",
            "Trainable params: 2,146,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10381/10381 [==============================] - 16s 2ms/step - loss: 57.9336 - mean_absolute_error: 4.0653\n",
            "Epoch 2/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 36.6238 - mean_absolute_error: 3.4140\n",
            "Epoch 3/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 31.1129 - mean_absolute_error: 3.3420\n",
            "Epoch 4/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 29.5711 - mean_absolute_error: 3.2761\n",
            "Epoch 5/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 27.6367 - mean_absolute_error: 3.1675\n",
            "Epoch 6/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 25.2167 - mean_absolute_error: 2.9238\n",
            "Epoch 7/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 20.7670 - mean_absolute_error: 2.6849\n",
            "Epoch 8/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 18.0185 - mean_absolute_error: 2.4576\n",
            "Epoch 9/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 16.3796 - mean_absolute_error: 2.3173\n",
            "Epoch 10/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 15.0465 - mean_absolute_error: 2.2392\n",
            "Epoch 11/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 13.4931 - mean_absolute_error: 2.1243\n",
            "Epoch 12/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 13.0504 - mean_absolute_error: 2.0814\n",
            "Epoch 13/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 12.7920 - mean_absolute_error: 2.0407\n",
            "Epoch 14/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 12.2083 - mean_absolute_error: 1.9833\n",
            "Epoch 15/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 11.0229 - mean_absolute_error: 1.9126\n",
            "Epoch 16/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 11.2922 - mean_absolute_error: 1.9125\n",
            "Epoch 17/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 10.6172 - mean_absolute_error: 1.8652\n",
            "Epoch 18/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 10.5315 - mean_absolute_error: 1.8353\n",
            "Epoch 19/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 10.0894 - mean_absolute_error: 1.7962\n",
            "Epoch 20/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 10.3730 - mean_absolute_error: 1.8023\n",
            "Epoch 21/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.9232 - mean_absolute_error: 1.7669\n",
            "Epoch 22/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.6689 - mean_absolute_error: 1.7424\n",
            "Epoch 23/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.3698 - mean_absolute_error: 1.7035\n",
            "Epoch 24/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 9.1592 - mean_absolute_error: 1.6790\n",
            "Epoch 25/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.5284 - mean_absolute_error: 1.7030\n",
            "Epoch 26/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.9833 - mean_absolute_error: 1.6640\n",
            "Epoch 27/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.9253 - mean_absolute_error: 1.6357\n",
            "Epoch 28/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.4242 - mean_absolute_error: 1.6110\n",
            "Epoch 29/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.8926 - mean_absolute_error: 1.6434\n",
            "Epoch 30/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.5700 - mean_absolute_error: 1.6024\n",
            "Epoch 31/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.5430 - mean_absolute_error: 1.5973\n",
            "Epoch 32/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.2429 - mean_absolute_error: 1.5922\n",
            "Epoch 33/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.5823 - mean_absolute_error: 1.5902\n",
            "Epoch 34/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.8322 - mean_absolute_error: 1.5691\n",
            "Epoch 35/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.0393 - mean_absolute_error: 1.5637\n",
            "Epoch 36/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.4962 - mean_absolute_error: 1.5323\n",
            "Epoch 37/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.1878 - mean_absolute_error: 1.5582\n",
            "Epoch 38/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 8.2642 - mean_absolute_error: 1.5745\n",
            "Epoch 39/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.5340 - mean_absolute_error: 1.5227\n",
            "Epoch 40/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.8523 - mean_absolute_error: 1.5401\n",
            "Epoch 41/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.8535 - mean_absolute_error: 1.5409\n",
            "Epoch 42/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.7084 - mean_absolute_error: 1.5220\n",
            "Epoch 43/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.8582 - mean_absolute_error: 1.5343\n",
            "Epoch 44/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.7198 - mean_absolute_error: 1.5217\n",
            "Epoch 45/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.7877 - mean_absolute_error: 1.5339\n",
            "Epoch 46/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.6673 - mean_absolute_error: 1.5132\n",
            "Epoch 47/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.6506 - mean_absolute_error: 1.5108\n",
            "Epoch 48/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.7962 - mean_absolute_error: 1.5303\n",
            "Epoch 49/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 7.7233 - mean_absolute_error: 1.5303\n",
            "Epoch 50/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.5954 - mean_absolute_error: 1.5061\n",
            "Mean squared error: 5.68\n",
            "Explained Variance: 0.93\n",
            "Kappa Score: 0.96\n",
            "###################Fold 5##################\n",
            "\n",
            "Training Word2Vec Model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_15 (LSTM)               (None, 1, 500)            2002000   \n",
            "_________________________________________________________________\n",
            "lstm_16 (LSTM)               (None, 64)                144640    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,146,705\n",
            "Trainable params: 2,146,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "10381/10381 [==============================] - 17s 2ms/step - loss: 59.0207 - mean_absolute_error: 4.1179\n",
            "Epoch 2/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 37.1447 - mean_absolute_error: 3.4363\n",
            "Epoch 3/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 31.1738 - mean_absolute_error: 3.3265\n",
            "Epoch 4/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 28.2569 - mean_absolute_error: 3.2267\n",
            "Epoch 5/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 26.0148 - mean_absolute_error: 3.0370\n",
            "Epoch 6/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 23.7880 - mean_absolute_error: 2.8523\n",
            "Epoch 7/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 20.9852 - mean_absolute_error: 2.6514\n",
            "Epoch 8/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 17.8688 - mean_absolute_error: 2.4229\n",
            "Epoch 9/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 15.8719 - mean_absolute_error: 2.3104\n",
            "Epoch 10/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 14.4941 - mean_absolute_error: 2.2079\n",
            "Epoch 11/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 14.1447 - mean_absolute_error: 2.1527\n",
            "Epoch 12/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 13.4490 - mean_absolute_error: 2.0875\n",
            "Epoch 13/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 12.9254 - mean_absolute_error: 2.0375\n",
            "Epoch 14/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 12.1385 - mean_absolute_error: 1.9867\n",
            "Epoch 15/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 11.5119 - mean_absolute_error: 1.9495\n",
            "Epoch 16/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 11.0121 - mean_absolute_error: 1.9029\n",
            "Epoch 17/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 10.8065 - mean_absolute_error: 1.8663\n",
            "Epoch 18/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 10.9314 - mean_absolute_error: 1.8606\n",
            "Epoch 19/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 10.8019 - mean_absolute_error: 1.8349\n",
            "Epoch 20/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 9.8069 - mean_absolute_error: 1.7618\n",
            "Epoch 21/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 10.1765 - mean_absolute_error: 1.7776\n",
            "Epoch 22/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.9340 - mean_absolute_error: 1.7551\n",
            "Epoch 23/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.8969 - mean_absolute_error: 1.7517\n",
            "Epoch 24/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.4735 - mean_absolute_error: 1.7152\n",
            "Epoch 25/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 9.2944 - mean_absolute_error: 1.7015\n",
            "Epoch 26/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 9.2197 - mean_absolute_error: 1.6675\n",
            "Epoch 27/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.8796 - mean_absolute_error: 1.6583\n",
            "Epoch 28/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 9.3842 - mean_absolute_error: 1.6656\n",
            "Epoch 29/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 9.2453 - mean_absolute_error: 1.6579\n",
            "Epoch 30/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.9285 - mean_absolute_error: 1.6429\n",
            "Epoch 31/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.6528 - mean_absolute_error: 1.6130\n",
            "Epoch 32/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.4630 - mean_absolute_error: 1.6091\n",
            "Epoch 33/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.5107 - mean_absolute_error: 1.6178\n",
            "Epoch 34/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 8.3741 - mean_absolute_error: 1.5833\n",
            "Epoch 35/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 8.1381 - mean_absolute_error: 1.5717\n",
            "Epoch 36/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 8.7067 - mean_absolute_error: 1.5990\n",
            "Epoch 37/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.9270 - mean_absolute_error: 1.5777\n",
            "Epoch 38/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.1256 - mean_absolute_error: 1.5790\n",
            "Epoch 39/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 8.2441 - mean_absolute_error: 1.5724\n",
            "Epoch 40/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.0769 - mean_absolute_error: 1.5781\n",
            "Epoch 41/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.3232 - mean_absolute_error: 1.5764\n",
            "Epoch 42/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.9805 - mean_absolute_error: 1.5530\n",
            "Epoch 43/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 7.5960 - mean_absolute_error: 1.5503\n",
            "Epoch 44/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 7.8984 - mean_absolute_error: 1.5452\n",
            "Epoch 45/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 8.0158 - mean_absolute_error: 1.5555\n",
            "Epoch 46/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 8.0543 - mean_absolute_error: 1.5491\n",
            "Epoch 47/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.5032 - mean_absolute_error: 1.5249\n",
            "Epoch 48/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.8697 - mean_absolute_error: 1.5402\n",
            "Epoch 49/50\n",
            "10381/10381 [==============================] - 13s 1ms/step - loss: 7.8484 - mean_absolute_error: 1.5323\n",
            "Epoch 50/50\n",
            "10381/10381 [==============================] - 12s 1ms/step - loss: 7.4489 - mean_absolute_error: 1.4966\n",
            "Mean squared error: 5.81\n",
            "Explained Variance: 0.93\n",
            "Kappa Score: 0.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYosZ4u2pVnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}